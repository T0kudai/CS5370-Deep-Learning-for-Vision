{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Question_2.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"WEpvOceUf0lE"},"source":["#### **Welcome to Assignment 6 - Question 2, on Deep Learning for Computer Vision.**\n","In this assignment you will get a chance to implement Projected Gradient Descent and Rotation based Self Supervised Learning Technique .\n","\n","#### **Instructions**\n","1. Use Python 3.x to run this notebook\n","3. Write your code only in between the lines 'YOUR CODE STARTS HERE' and 'YOUR CODE ENDS HERE'.Necessary comments are provided within the lines to help you in the implementation, you sould not change anything else code cells, if you do, the answers you are supposed to get at the end of this assignment might be wrong.\n","4. Read documentation of each function carefully.\n","5. All the Best!\n","6. Total Marks: 11"]},{"cell_type":"markdown","metadata":{"id":"nzaL9YMibBNB"},"source":["### Question 1 : Implement Projected Gradient Descent\n","\n","Given a sample test image and a pretrained model, generate a corresponding adversarial image using Projected gradient Descent(PGD). The following attack configuration MUST be follwed in order to generate the adversarial image: step size = 2/255, epsilon = 0.3 and number_of_steps = 40. \n"," "]},{"cell_type":"code","metadata":{"id":"WFlqZejQI3XE"},"source":["# 4-Mark"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MlqzGiwscpb5","colab":{"base_uri":"https://localhost:8080/","height":809},"executionInfo":{"status":"ok","timestamp":1619434620651,"user_tz":-330,"elapsed":10449,"user":{"displayName":"Vishal Singh Yadav","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiKS8PPArcaXSHoPllGM82MyqAIWTxqm-r7Q67q=s64","userId":"13126174056928348042"}},"outputId":"4098d367-5c5a-45c9-bd6c-05d9e1cde5b5"},"source":["!wget www.di.ens.fr/~lelarge/MNIST.tar.gz\n","!tar -zxvf MNIST.tar.gz\n","\n","from __future__ import print_function\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torchvision import datasets, transforms\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import numpy as np\n","\n","# Set for testing purposes, please do not change!\n","seed = 0\n","torch.manual_seed(seed)\n","torch.cuda.manual_seed(seed)\n","torch.cuda.manual_seed_all(seed)\n","np.random.seed(seed)\n","torch.backends.cudnn.deterministic = True\n","torch.backends.cudnn.benchmark = False\n","\n","\n","epsilons = 0.3\n","pretrained_model = \"lenet_mnist_model.pth\"\n","use_cuda=True\n","\n","# LeNet Model definition\n","class Net(nn.Module):\n","    def __init__(self):\n","        super(Net, self).__init__()\n","        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n","        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n","        self.conv2_drop = nn.Dropout2d()\n","        self.fc1 = nn.Linear(320, 50)\n","        self.fc2 = nn.Linear(50, 10)\n","\n","    def forward(self, x):\n","        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n","        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n","        x = x.view(-1, 320)\n","        x = F.relu(self.fc1(x))\n","        x = F.dropout(x, training=self.training)\n","        x = self.fc2(x)\n","        return x\n","        #return F.log_softmax(x, dim=1)\n","\n","# The following block is to mitigate the temporary issue within PyTorch about downloading MNIST. Don't change!\n","new_mirror = 'https://ossci-datasets.s3.amazonaws.com/mnist'\n","datasets.MNIST.resources = [\n","   ('/'.join([new_mirror, url.split('/')[-1]]), md5)\n","   for url, md5 in datasets.MNIST.resources\n","]\n","# MNIST Test dataset and dataloader declaration\n","test_loader = torch.utils.data.DataLoader(\n","    datasets.MNIST('.', train=False, download=True, transform=transforms.Compose([\n","            transforms.ToTensor(),\n","            ])), \n","        batch_size=1, shuffle=True)\n","\n","# Define what device we are using\n","print(\"CUDA Available: \",torch.cuda.is_available())\n","device = torch.device(\"cuda\" if (use_cuda and torch.cuda.is_available()) else \"cpu\")\n","\n","# Initialize the network\n","model = Net().to(device)\n","\n","# Load the pretrained model\n","model.load_state_dict(torch.load(pretrained_model, map_location='cpu'))\n","\n","# Set the model in evaluation mode. In this case this is for the Dropout layers\n","model.eval()\n","\n","## Implement Projected Gradient Descent algorithm\n","\n","### YOUR CODE STARTS HERE\n","def PGD_attack(data, target, model):\n","    step_size = 2/255\n","    epsilon = 0.3\n","    number_of_steps = 40\n","\n","    data = data.detach()\n","    target = target.detach()\n","    loss = nn.CrossEntropyLoss()\n","    adv_data = data.detach()\n","\n","    for i in range(number_of_steps):\n","        adv_data.requires_grad = True\n","        outputs = model(adv_data)\n","        cost = -1*loss(outputs, target)\n","\n","        grad = torch.autograd.grad(cost, adv_data)[0]\n","\n","        adv_data = adv_data.detach() - step_size*grad.sign()\n","        pertub = torch.clamp(adv_data - data, -epsilon, epsilon)\n","        adv_data = torch.clamp(data + pertub, 0, 1).detach()\n","\n","    return adv_data\n","\n","### YOUR CODE ENDS HERE\n","\n","def test( model, device, data, target, epsilon ):\n","\n","    # Accuracy counter\n","    correct = 0\n","    adv_examples = []\n","\n","    # Send the data and label to the device\n","    data, target = data.to(device), target.to(device)\n","\n","    # Set requires_grad attribute of tensor. Important for Attack\n","    data.requires_grad = True\n","\n","    # Forward pass the data through the model\n","    output = model(data)\n","    init_pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n","\n","    ### generate the perturbed image using PGD    \n","    perturbed_data = PGD_attack(data, target, model)\n","        \n","    # Re-classify the perturbed image\n","    output = model(perturbed_data)\n","\n","    # Check for success\n","    final_pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n","    if final_pred.item() == target.item():\n","        correct += 1\n","    else:\n","        pass\n","    # Return the accuracy and an adversarial example\n","    return final_pred, perturbed_data\n","\n","for data,target, in test_loader:\n","    data = data[0:1,:,:,:]\n","    target = target[0:1]\n","    break\n","\n","\n","pred_adv, adv_ex = test(model, device, data,target, epsilons)\n","print (\"Predicted class for perturbed image: \",pred_adv)\n","\n","\n","### YOUR CODE STARTS HERE\n","\n","\n","#Compute the mean pixel value of the adversarial image and print the value\n","print(torch.mean(adv_ex))\n","\n","#Visualize the adversarial image, show the image\n","plt.imshow(adv_ex.reshape(28,28).cpu().data.numpy(), cmap=\"gray\")\n","\n","\n","### YOUR CODE ENDS HERE"],"execution_count":null,"outputs":[{"output_type":"stream","text":["--2021-04-26 10:56:51--  http://www.di.ens.fr/~lelarge/MNIST.tar.gz\n","Resolving www.di.ens.fr (www.di.ens.fr)... 129.199.99.14\n","Connecting to www.di.ens.fr (www.di.ens.fr)|129.199.99.14|:80... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://www.di.ens.fr/~lelarge/MNIST.tar.gz [following]\n","--2021-04-26 10:56:52--  https://www.di.ens.fr/~lelarge/MNIST.tar.gz\n","Connecting to www.di.ens.fr (www.di.ens.fr)|129.199.99.14|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: unspecified [application/x-gzip]\n","Saving to: ‘MNIST.tar.gz.4’\n","\n","MNIST.tar.gz.4          [            <=>     ]  33.20M  6.38MB/s    in 5.5s    \n","\n","2021-04-26 10:56:58 (6.09 MB/s) - ‘MNIST.tar.gz.4’ saved [34813078]\n","\n","MNIST/\n","MNIST/raw/\n","MNIST/raw/train-labels-idx1-ubyte\n","MNIST/raw/t10k-labels-idx1-ubyte.gz\n","MNIST/raw/t10k-labels-idx1-ubyte\n","MNIST/raw/t10k-images-idx3-ubyte.gz\n","MNIST/raw/train-images-idx3-ubyte\n","MNIST/raw/train-labels-idx1-ubyte.gz\n","MNIST/raw/t10k-images-idx3-ubyte\n","MNIST/raw/train-images-idx3-ubyte.gz\n","MNIST/processed/\n","MNIST/processed/training.pt\n","MNIST/processed/test.pt\n","CUDA Available:  False\n","Predicted class for perturbed image:  tensor([[8]])\n","tensor(0.1600)\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<matplotlib.image.AxesImage at 0x7f5046ddefd0>"]},"metadata":{"tags":[]},"execution_count":29},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"vETOukxZI3XG"},"source":["### Question 1 (1 mark): Find out the predicted class when the adversarial image generated in the previous step is fed to the pretrained model ? "]},{"cell_type":"markdown","metadata":{"id":"Dwz8Ltmvx75-"},"source":["We get predicted class as tensor([[8]]) as given above. So the predicted class is 8."]},{"cell_type":"markdown","metadata":{"id":"Abm7O-0ngxJC"},"source":["### Question 2 (1 mark): Visualize The adversarial image generated  using the exactly same setup as in previous question and find out the mean pixel intensity of that adversarial image?"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":316},"id":"LVIBMQOnyoa9","executionInfo":{"status":"ok","timestamp":1619434638334,"user_tz":-330,"elapsed":1219,"user":{"displayName":"Vishal Singh Yadav","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiKS8PPArcaXSHoPllGM82MyqAIWTxqm-r7Q67q=s64","userId":"13126174056928348042"}},"outputId":"8ed644ac-d46b-424f-f4a5-a6b801e1fd43"},"source":["print(\"Mean pixel intensity: \",torch.mean(adv_ex).item())\n","\n","print(\"Generated adversial image: \")\n","plt.imshow(adv_ex.reshape(28,28).cpu().data.numpy(), cmap=\"gray\")\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mean pixel intensity:  0.15995147824287415\n","Generated adversial image: \n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<matplotlib.image.AxesImage at 0x7f5046ec6210>"]},"metadata":{"tags":[]},"execution_count":30},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"PcH8ExwPa_fv"},"source":["### Question:3 Rotation Based Self Supervision Task"]},{"cell_type":"markdown","metadata":{"id":"i90RbhebygQM"},"source":["\n","Please consider the modified LeNet model with below model definition:\n","\n","Shared layers (1 to 4)\n","\n","\n","1.   Conv layer with 10 output channels and filter size 5\n","2.   Conv layer with 20 output channels and filter size 5\n","3.   Dropout layer\n","4.   Fully connected layer with output size 50\n","5.   Branch out 2 heads i.e. main classification and rotation  classification heads.\n","\n","  *   Takes input from step 4 and outputs 10 dimensions(main class labels) through a fully connected layer\n","  *   Takes input from step 4 and outputs 4 dimensions(rotation class labels) through a fully connected layer\n","\n"," \n","\n","This model is basically a Y-shaped model where the trail is shared layers and 2 heads are for main classification and rotation classification. \n","A model with above definition is trained for 20 epochs and the resulting trained model is shared with you. \n","Some steps in the forward function are kept blank for you to fill up. You have to load the model and properly, write those steps in the forward function to be able to run the model. Please note that without these steps properly written, you won't be able to run the model. Once you do this, please answer the below question.\n","\n"]},{"cell_type":"code","metadata":{"id":"0FT6RLGMI3XH"},"source":["# 4-Mark"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RHJUKyLuxxfw","executionInfo":{"status":"ok","timestamp":1619450693274,"user_tz":-330,"elapsed":7600,"user":{"displayName":"Vishal Singh Yadav","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiKS8PPArcaXSHoPllGM82MyqAIWTxqm-r7Q67q=s64","userId":"13126174056928348042"}},"outputId":"24aa5c51-57eb-42e7-940b-929280c68ce6"},"source":["!wget www.di.ens.fr/~lelarge/MNIST.tar.gz\n","!tar -zxvf MNIST.tar.gz"],"execution_count":null,"outputs":[{"output_type":"stream","text":["--2021-04-26 15:24:48--  http://www.di.ens.fr/~lelarge/MNIST.tar.gz\n","Resolving www.di.ens.fr (www.di.ens.fr)... 129.199.99.14\n","Connecting to www.di.ens.fr (www.di.ens.fr)|129.199.99.14|:80... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://www.di.ens.fr/~lelarge/MNIST.tar.gz [following]\n","--2021-04-26 15:24:48--  https://www.di.ens.fr/~lelarge/MNIST.tar.gz\n","Connecting to www.di.ens.fr (www.di.ens.fr)|129.199.99.14|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: unspecified [application/x-gzip]\n","Saving to: ‘MNIST.tar.gz’\n","\n","MNIST.tar.gz            [             <=>    ]  33.20M  10.4MB/s    in 3.2s    \n","\n","2021-04-26 15:24:52 (10.4 MB/s) - ‘MNIST.tar.gz’ saved [34813078]\n","\n","MNIST/\n","MNIST/raw/\n","MNIST/raw/train-labels-idx1-ubyte\n","MNIST/raw/t10k-labels-idx1-ubyte.gz\n","MNIST/raw/t10k-labels-idx1-ubyte\n","MNIST/raw/t10k-images-idx3-ubyte.gz\n","MNIST/raw/train-images-idx3-ubyte\n","MNIST/raw/train-labels-idx1-ubyte.gz\n","MNIST/raw/t10k-images-idx3-ubyte\n","MNIST/raw/train-images-idx3-ubyte.gz\n","MNIST/processed/\n","MNIST/processed/training.pt\n","MNIST/processed/test.pt\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"sGCwb_6by8B6","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619454847669,"user_tz":-330,"elapsed":10371,"user":{"displayName":"Vishal Singh Yadav","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiKS8PPArcaXSHoPllGM82MyqAIWTxqm-r7Q67q=s64","userId":"13126174056928348042"}},"outputId":"77c61f8f-1d68-4bcc-b20d-978d1f6f9024"},"source":["# -*- coding: utf-8 -*-\n","\n","from __future__ import print_function\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torchvision import datasets, transforms\n","import numpy as np\n","# import matplotlib.pyplot as plt\n","import torch.utils.data\n","import numpy as np\n","\n","\n","import torchvision\n","import torchvision.transforms as transforms\n","torch.manual_seed(1)\n","\n","# Assumes that tensor is (nchannels, height, width)\n","def tensor_rot_90(x):\n","    return x.flip(2).transpose(1, 2)\n","\n","def tensor_rot_180(x):\n","    return x.flip(2).flip(1)\n","\n","def tensor_rot_270(x):\n","    return x.transpose(1, 2).flip(2)\n","\n","def rotate_batch_with_labels(batch, labels):\n","    images = []\n","    for img, label in zip(batch, labels):\n","        if label == 1:\n","            img = tensor_rot_90(img)\n","        elif label == 2:\n","            img = tensor_rot_180(img)\n","        elif label == 3:\n","            img = tensor_rot_270(img)\n","        images.append(img.unsqueeze(0))\n","    return torch.cat(images)\n","\n","def rotate_batch(batch, label):\n","    if label == 'rand':\n","        labels = torch.randint(4, (len(batch),), dtype=torch.long)\n","    elif label == 'expand':\n","        labels = torch.cat([torch.zeros(len(batch), dtype=torch.long),\n","                    torch.zeros(len(batch), dtype=torch.long) + 1,\n","                    torch.zeros(len(batch), dtype=torch.long) + 2,\n","                    torch.zeros(len(batch), dtype=torch.long) + 3])\n","        batch = batch.repeat((4,1,1,1))\n","    else:\n","        assert isinstance(label, int)\n","        labels = torch.zeros((len(batch),), dtype=torch.long) + label\n","    return rotate_batch_with_labels(batch, labels), labels\n","\n","# LeNet Model definition\n","class Net(nn.Module):\n","    def __init__(self):\n","        super(Net, self).__init__()\n","        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n","        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n","        self.conv2_drop = nn.Dropout2d()\n","        self.fc1 = nn.Linear(320, 50)\n","        self.fc2 = nn.Linear(50, 10)\n","        self.fc2_ssl = nn.Linear(50, 4)\n","\n","    ### network architecture for classification head: \n","    ### conv1 -> maxpool2D-> Relu->conv2->conv2_drop->maxpool2D->Relu->Reshape->fc1->Relu->dropout->fc2,fc2_ssl\n","    def forward(self, x):\n","        ### YOUR CODE STARTS HERE\n","        out = F.relu(F.max_pool2d(self.conv1(x), 2))\n","        out = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(out)), 2))\n","        out = out.view(-1, 320)\n","        out = F.dropout(F.relu(self.fc1(out)))\n","        x1 = self.fc2(out)\n","        x2 = self.fc2_ssl(out)\n","\n","        return x1,x2\n","\n","        ### YOUR CODE ENDS HERE\n","\n","# MNIST Test dataset and dataloader declaration\n","transform = transforms.Compose([\n","   transforms.ToTensor(),\n","   transforms.Normalize((0.1307,), (0.3081,))\n","])\n","\n","# the datasets\n","trainset = torchvision.datasets.MNIST(root='.', train=True, download=True, transform=transform)\n","trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True, num_workers=2)\n","\n","testset = torchvision.datasets.MNIST(root='.', train=False, download=False, transform=transform)\n","testloader = torch.utils.data.DataLoader(testset, batch_size=128, shuffle=False, num_workers=2)\n","\n","# Define what device we are using\n","print(\"CUDA Available: \",torch.cuda.is_available())\n","device = torch.device(\"cuda\" if (torch.cuda.is_available()) else \"cpu\")\n","\n","# Initialize the network\n","net = Net().to(device)\n","\n","parameters = list(net.parameters())\n","optimizer = optim.SGD(parameters, lr=0.1, momentum=0.9, weight_decay=5e-4)\n","\n","criterion = nn.CrossEntropyLoss().to(device)\n","print('Running...')\n","\n","def train(epoch):\n","    net.train()    \n","    \n","    for batch_idx, (inputs, labels) in enumerate(trainloader):\n","        optimizer.zero_grad()\n","        \n","        inputs, labels = inputs.to(device), labels.to(device)        \n","        labels_full = labels.repeat(4)            \n","        \n","        ## Self supervised head\n","        inputs_ssh, labels_ssh = rotate_batch(inputs, \"expand\")\n","        inputs_ssh, labels_ssh = inputs_ssh.to(device), labels_ssh.to(device)\n","        # outputs_clh , outputs_ssh denotes classification head output and self supervision head output respectively \n","        outputs_clh, outputs_ssh = net(inputs_ssh) \n","        loss = criterion(outputs_clh, labels_full)\n","        loss_ssh = criterion(outputs_ssh, labels_ssh)\n","        loss += loss_ssh\n","\n","        loss.backward()\n","        optimizer.step()\n","\n","    print(('Epoch %d: %f' %(epoch,loss.item())))\n","    torch.save(net, \"ssl_mnist.pt\")\n","\n","\n","## Funtion to compute test accuracy using model already trained with additional self-supervised head..\n","def test():\n","    main_correct = 0\n","    class_correct = 0\n","\n","    ### YOUR CODE STARTS HERE\n","    model = torch.load(\"./ssl_mnist.pt\", map_location='cpu')\n","    model.to(device)\n","    model.eval()\n","    # net.load_state_dict(torch.load(\"./ssl_mnist.pt\", map_location='cpu'))\n","    # net.eval()\n","    with torch.no_grad():\n","        for batch_idx, (inputs, labels) in enumerate(testloader):\n","            inputs, labels = inputs.to(device), labels.to(device)        \n","            labels_full = labels.repeat(4)            \n","            \n","            ## Self supervised head\n","            inputs_ssh, labels_ssh = rotate_batch(inputs, \"expand\")\n","            inputs_ssh, labels_ssh = inputs_ssh.to(device), labels_ssh.to(device)\n","            # outputs_clh , outputs_ssh denotes classification head output and self supervision head output respectively \n","            main_labels, class_labels = net(inputs_ssh) \n","            # print(main_labels.shape)\n","            # print(labels_full.shape)\n","            \n","            _, main_pred_labels = torch.max(main_labels,dim=1)\n","            main_correct += (main_pred_labels == labels_full).sum()\n","            \n","            _, class_pred_labels = torch.max(class_labels, dim=1)\n","            class_correct += (class_pred_labels == labels_ssh).sum()\n","    \n","    return main_correct, class_correct, len(testloader.dataset)\n","        \n","    ### YOUR CODE ENDS HERE\n","\n","### Training Loop\n","# for epoch in range(0, 20):\n","#     train(epoch)\n","\n","# train(1)\n","main_correct, class_correct, num_samples = test()\n","\n","print(\"Classification head accuracy: \", (100. * main_correct / num_samples).item())\n","print(\"Self supervision accuracy: \", (100. * class_correct / num_samples).item())"],"execution_count":null,"outputs":[{"output_type":"stream","text":["CUDA Available:  False\n","Running...\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torch/serialization.py:623: UserWarning: Couldn't retrieve source code for container of type Net. It won't be checked for correctness upon loading.\n","  \"type \" + container_type.__name__ + \". It won't be checked \"\n","/usr/local/lib/python3.7/dist-packages/torch/serialization.py:656: SourceChangeWarning: source code of class 'torch.nn.modules.conv.Conv2d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n","  warnings.warn(msg, SourceChangeWarning)\n","/usr/local/lib/python3.7/dist-packages/torch/serialization.py:656: SourceChangeWarning: source code of class 'torch.nn.modules.dropout.Dropout2d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n","  warnings.warn(msg, SourceChangeWarning)\n","/usr/local/lib/python3.7/dist-packages/torch/serialization.py:656: SourceChangeWarning: source code of class 'torch.nn.modules.linear.Linear' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n","  warnings.warn(msg, SourceChangeWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["Classification head accuracy:  43.97999954223633\n","Self supervision accuracy:  97.12000274658203\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"BW6bzewYI3XI"},"source":["### 1-Mark\n","### What is the model test accuracy on MNIST test dataset"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WvdqiZ2yBULR","executionInfo":{"status":"ok","timestamp":1619454855034,"user_tz":-330,"elapsed":1373,"user":{"displayName":"Vishal Singh Yadav","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiKS8PPArcaXSHoPllGM82MyqAIWTxqm-r7Q67q=s64","userId":"13126174056928348042"}},"outputId":"bf974571-b32b-4e9d-bc29-cc52260bcbc8"},"source":["print(\"Classification head accuracy: \", (100. * main_correct / num_samples).item())\n","print(\"Self supervision accuracy: \", (100. * class_correct / num_samples).item())"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Classification head accuracy:  43.97999954223633\n","Self supervision accuracy:  97.12000274658203\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Ed35arqfBV1O"},"source":[""],"execution_count":null,"outputs":[]}]}